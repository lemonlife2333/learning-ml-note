{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 简单线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单线性模型，就是一阶线性回归。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单线性回归：   \n",
    "- 模型：y=a*x+b\n",
    "- 代价函数：J=$ \\sum_{i=1}^{m}(a*x+b-y)^2 $ \n",
    "- a=$ \\frac{\\sum_{i=1}^{m}(x-\\bar x)*(y-\\bar y)}{(\\sum_{i=1}^{m}(x-\\bar x)^2}$    \n",
    " or  a=$ \\frac{(X-\\bar X).(Y-\\bar Y)}{(X-\\bar X)^2} $\n",
    "- b=$ \\bar y-a*\\bar x $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class simplelinear:\n",
    "    def __init__(self):\n",
    "        self.a_ = None\n",
    "        self.b_ = None\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        x_mean = np.mean(x_train)\n",
    "        y_mean = np.mean(y_train)\n",
    "        nums = 0\n",
    "        d = 0\n",
    "#          for x, y in zip(x_train, y_train):\n",
    "#             num += (x - x_mean) * (y - y_mean)\n",
    "#             d += (x - x_mean) ** 2\n",
    "        # 正规方程解\n",
    "        self.a_ = (x_train-x_mean).dot(y_train-y_mean) / \\\n",
    "            (x_train - x_mean).dot(x_train - x_mean)\n",
    "        self.b_ = y_mean-self.a_*x_mean\n",
    "        return self\n",
    "\n",
    "    def predict_(self, x_test):\n",
    "\n",
    "        y_predict = [self.a_*x+self.b_ for x in x_test]\n",
    "        return np.array(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1., 2., 3., 4., 5.])\n",
    "y = np.array([1., 3., 2., 3., 5.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.2, 2. , 2.8, 3.6, 4.4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple=simplelinear()\n",
    "simple.fit(x,y)\n",
    "simple.predict_(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple.a_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39999999999999947"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple.b_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.plot(x, simple.predict_(x), color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多元线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多元线性回归可写成:\n",
    "\n",
    "$\\hat{y}(\\theta, x) = \\theta_0 + \\theta_1 x^1 +\\theta_2 x^2 +\\theta_3 x^3 +\\theta_4 x^4 +...+\\theta_n x^n$  \n",
    "\n",
    "也可写成：  \n",
    "\n",
    "$\\hat{Y}=X.\\theta$\n",
    "\n",
    "$\\hat{Y^i} = X^i.\\theta$  \n",
    "其中，$\\theta=(\\theta_0,...,\\theta_n)^\\top$ 是$n\\times1$的列向量  \n",
    "$X^i=(1,x^1,...,x^n)$ ,X为 $m\\times n$ 的矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代价函数：$J(\\theta,X)= \\sum_{i=0}^n (Y^i-\\hat{Y^i})^\\top.(Y^i-\\hat{Y^i})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正规方程解：$\\theta=inv(X_b^\\top X_b)X_b^\\top Y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据上述表达得到如下代码\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Linear:\n",
    "    def __inint__(self):\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.theta_ = None\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        x_b = np.hstack([np.ones((len(x_train), 1)), x_train])\n",
    "#         同理，正规方程解\n",
    "        self.theta_ = np.linalg.inv(x_b.T.dot(x_b)).dot(x_b.T).dot(y_train)\n",
    "        self.intercept_ = self.theta_[0]\n",
    "        self.coef_ = self.theta_[1:]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, x_predict):\n",
    "        x_b = np.hstack([np.ones((len(x_predict), 1)), x_predict])\n",
    "        return x_b.dot(self.theta_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "boston = datasets.load_boston()\n",
    "\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Linear at 0x22e7f99ff60>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg=Linear()\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.30356663e-01,  4.36387787e-02,  2.21747594e-02,  3.17396478e+00,\n",
       "       -1.76672950e+01,  3.84628517e+00, -4.92171802e-03, -1.37010653e+00,\n",
       "        2.84824614e-01, -1.08997373e-02, -9.47411635e-01,  1.06620242e-02,\n",
       "       -4.57622903e-01])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.18041338505329"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn 学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 普通最小二乘   \n",
    "- sklearn.linear_model.LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=None)    \n",
    "         参数：\t\n",
    "        fit_intercept ： boolean，optional，默认为True\n",
    "        是否计算此模型的截距。如果设置为False，则不会在计算中使用截距（例如，预计数据已经居中）。\n",
    "\n",
    "        normalize ： 布尔值，可选，默认为False\n",
    "        fit_intercept设置为False 时，将忽略此参数。如果为True，则回归量X将在回归之前通过减去平均值并除以l2范数来归一化。如果您希望标准化，请 在使用估算器sklearn.preprocessing.StandardScaler之前fit使用normalize=False。\n",
    "\n",
    "        copy_X ： 布尔值，可选，默认为True\n",
    "        如果为True，则将复制X; 否则，它可能会被覆盖。\n",
    "\n",
    "        n_jobs ： int或None，可选（默认=无）\n",
    "        用于计算的作业数。这只会为n_targets> 1和足够大的问题提供加速。 None除非在joblib.parallel_backend上下文中，否则表示1 。 -1表示使用所有处理器。有关 详细信息，请参阅词汇表。\n",
    "\n",
    "        属性：\t\n",
    "        coef_ ： array，shape（n_features，）或（n_targets，n_features）\n",
    "        线性回归问题的估计系数。如果在拟合期间传递多个目标（y 2D），则这是形状的二维数组（n_targets，n_features），而如果仅传递一个目标，则这是长度为n_features的一维数组。\n",
    "\n",
    "        intercept_ ： array\n",
    "        线性模型中的独立项。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "a=[[1,1],[2,3],[3,2],[4,3],[5,5]]\n",
    "reg.fit(a,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e+00, 1.40433339e-16])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.predict([[5,6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 岭回归 \n",
    "Ridge 回归通过对系数的大小施加惩罚来解决 普通最小二乘法 的一些问题。 岭系数最小化的是带罚项的残差平方和，\n",
    "\n",
    "$ \\underset{w}{min\\,} {{|| X w - y||_2}^2 + \\alpha {||w||_2}^2}$\n",
    "\n",
    "其中， $\\alpha \\geq 0 $是控制系数收缩量的复杂性参数： $\\alpha$ 的值越大，收缩量越大，模型对共线性的鲁棒性也更强。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.linear_model.Ridge(alpha=1.0, fit_intercept=True, normalize=False, copy_X=True, max_iter=None, tol=0.001, solver=’auto’, random_state=None)\n",
    "\n",
    "    max_iter ： int，可选\n",
    "    共轭梯度求解器的最大迭代次数。对于'sparse_cg'和'lsqr'解算器，默认值由scipy.sparse.linalg确定。对于'sag'解算器，默认值为1000。\n",
    "\n",
    "    tol ： float\n",
    "    解决方案的精确度。\n",
    "\n",
    "    求解器 ： {'auto'，'svd'，'cholesky'，'lsqr'，'sparse_cg'，'sag'，'saga'}\n",
    "    求解器用于计算程序：\n",
    "\n",
    "    'auto'  根据数据类型自动选择求解器。\n",
    "    'svd'  使用X的奇异值分解来计算岭系数。奇异矩阵比'cholesky'更稳定。\n",
    "    'cholesky'  使用标准的scipy.linalg.solve函数来获得封闭形式的解决方案。\n",
    "    'sparse_cg'  使用scipy.sparse.linalg.cg中的共轭梯度求解器。作为迭代算法，此解算器比“cholesky”更适合大规模数据（set tol和max_iter的可能性）。\n",
    "    'lsqr'  使用专用的正则化最小二乘例程scipy.sparse.linalg.lsqr。它是最快的并且使用迭代过程。\n",
    "    'sag'  使用随机平均梯度下降，'saga'使用其改进的，无偏见的版本SAGA。这两种方法也使用迭代过程，并且当n_samples和n_features都很大时，它们通常比其他求解器更快。请注意，“sag”和“saga”快速收敛仅在具有大致相同比例的要素上得到保证。您可以使用sklearn.preprocessing中的缩放器预处理数据。\n",
    "    所有最后五个求解器都支持密集和稀疏数据。但是，当fit_intercept为True 时，只有'sag'和'sparse_cg'支持稀疏输入。\n",
    "    \n",
    "    \n",
    "     random_state ： int，RandomState实例或None，可选，默认无\n",
    "    伪随机数生成器的种子，用于在混洗数据时使用。如果是int，则random_state是随机数生成器使用的种子; 如果是RandomState实例，则random_state是随机数生成器; 如果为None，则随机数生成器是由其使用的RandomState实例np.random。在solver=='sag'时使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.5, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.Ridge (alpha = .5)\n",
    "reg.fit ([[0, 0], [0, 0], [1, 1]], [0, .1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34545455, 0.34545455])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1363636363636364"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RidgeCV 通过内置的关于的 Alpha 参数的交叉验证来实现岭回归。 该对象与 GridSearchCV 的使用方法相同，只是它默认为 Generalized Cross-Validation(广义交叉验证 GCV)，这是一种有效的留一验证方法（LOO-CV）:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.RidgeCV(alphas=[0.1, 1.0, 10.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeCV(alphas=array([ 0.1,  1. , 10. ]), cv=None, fit_intercept=True,\n",
       "    gcv_mode=None, normalize=False, scoring=None, store_cv_values=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit([[0, 0], [0, 0], [1, 1]], [0, .1, 1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"burk\">指定cv属性的值将触发(通过GridSearchCV的)交叉验证，cv=n，即是n次交叉</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.alpha_  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso\n",
    "Lasso 是拟合稀疏系数的线性模型。 它在一些情况下是有用的，因为它倾向于使用具有较少参数值的情况，有效地减少给定解决方案所依赖变量的数量。 因此，Lasso 及其变体是压缩感知领域的基础。 在一定条件下，它可以恢复一组非零权重的精确集\n",
    "在数学公式表达上，它由一个带有 \\ell_1 先验的正则项的线性模型组成。 其最小化的目标函数是:\n",
    "\n",
    "$\\underset{w}{min\\,} { \\frac{1}{2n_{samples}} ||X w - y||_2 ^ 2 + \\alpha ||w||_1}$\n",
    "\n",
    "lasso estimate 解决了加上罚项 $\\alpha ||w||_1 $的最小二乘法的最小化，其中， $\\alpha$ 是一个常数， $||w||_1$ 是参数向量的 $\\ell_1-norm$ 范数。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.Lasso(alpha = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit([[0, 0], [1, 1]], [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.predict([[1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6, 0. ])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8400000000000001"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score([[0, 0], [1, 1]], [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso) 类实现使用了 coordinate descent （坐标下降算法）来拟合系数    \n",
    "对于较简单的任务，同样有用的是函数 [lasso_path](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.lasso_path.html#sklearn.linear_model.lasso_path) 。它能够通过搜索所有可能的路径上的值来计算系数。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "坐标下降法属于一种非梯度优化的方法，它在<span class=\"mark\">每步迭代中沿一个坐标的方向进行搜索</span>，通过<span class=\"mark\">循环使用不同的坐标</span>方法来达到目标函数的局部极小值。求导时<span class=\"mark\">只对一个维度(坐标轴方向)进行求导</span>,而固定其它维度,这样<span class=\"mark\">每次只优化一个分量.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**多任务Lasso**\n",
    "\n",
    "[MultiTaskLasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.MultiTaskLasso.html#sklearn.linear_model.MultiTaskLasso) 使用L1 / L2混合范数作为正则化器训练的多任务Lasso模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn 通过交叉验证来公开设置 Lasso alpha 参数的对象: [LassoCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html#sklearn.linear_model.LassoCV) 和 [LassoLarsCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLarsCV.html#sklearn.linear_model.LassoLarsCV)      \n",
    "[lars(最小角算法)](https://www.cnblogs.com/pinard/p/6018889.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoLars(alpha=0.1, copy_X=True, eps=2.220446049250313e-16,\n",
       "     fit_intercept=True, fit_path=True, max_iter=500, normalize=True,\n",
       "     positive=False, precompute='auto', verbose=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> from sklearn import linear_model\n",
    ">>> reg = linear_model.LassoLars(alpha=.1)\n",
    ">>> reg.fit([[0, 0], [1, 1]], [0, 1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71715729, 0.        ])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1414213562373094"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 弹性网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[弹性网络](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html#sklearn.linear_model.ElasticNet) 是一种使用 L1， L2 范数作为先验正则项训练的线性回归模型。 这种组合允许拟合到一个只有少量参数是非零稀疏的模型，就像 Lasso 一样，但是它仍然保持了一些类似于 Ridge 的正则性质。我们可利用 l1_ratio 参数控制 L1 和 L2 的凸组合。\n",
    "弹性网络在很多特征互相联系的情况下是非常有用的。Lasso 很可能只随机考虑这些特征中的一个，而弹性网络更倾向于选择两个。\n",
    "\n",
    "在实践中，Lasso 和 Ridge 之间权衡的一个优势是它允许在循环过程（Under rotate）中继承 Ridge 的稳定性。\n",
    "\n",
    "在这里，最小化的目标函数是\n",
    "\n",
    "$ \\underset{w}{min\\,} { \\frac{1}{2n_{samples}} ||X w - y||_2 ^ 2 + \\alpha \\rho ||w||_1 +\\frac{\\alpha(1-\\rho)}{2} ||w||_2 ^ 2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ElasticNetCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNetCV.html#sklearn.linear_model.ElasticNetCV) 类可以通过交叉验证来设置参数 alpha （ $ \\alpha$ ） 和 l1_ratio （ $\\rho$ ） 。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MultiTaskElasticNet 是一个对多回归问题估算稀疏参数的弹性网络: Y 是一个二维数组，形状是 (n_samples,n_tasks)。 其限制条件是和其他回归问题一样，是选择的特征，也称为 tasks 。\n",
    "\n",
    "从数学上来说， 它包含一个混合的 $\\ell_1 \\ell_2 $先验和 $\\ell_2$ 先验为正则项训练的线性模型 目标函数就是最小化:\n",
    "\n",
    "$\\underset{W}{min\\,} { \\frac{1}{2n_{samples}} ||X W - Y||_{Fro}^2 + \\alpha \\rho ||W||_{2 1} +\\frac{\\alpha(1-\\rho)}{2} ||W||_{Fro}^2}$\n",
    "\n",
    "在 [MultiTaskElasticNet](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.MultiTaskElasticNet.html#sklearn.linear_model.MultiTaskElasticNet) 类中的实现采用了坐标下降法求解参数。\n",
    "\n",
    "在 [MultiTaskElasticNetCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.MultiTaskElasticNet.html#sklearn.linear_model.MultiTaskElasticNet) 中可以通过交叉验证来设置参数 alpha （ $\\alpha$ ） 和 l1_ratio （ $\\rho$ ） 。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评价回归算法的指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "均方误差（Mean Square Error）[MSE](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error) ：$ \\frac{1}{2m}\\sum_{i = 0} ^m(y^i - h_\\theta (x^i))^2$   \n",
    "\n",
    "均方根误差（Root Mean Square Error）RMSE : $\\sqrt{MSE}$   \n",
    "\n",
    "平均绝对误差（Mean Absolute Error）[MAE](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error):  $\\frac{1}{2m}\\sum_{i = 0} ^m|y^i - h_\\theta (x^i)|$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述指标在面对不同类问题时会出现不适用  \n",
    "\n",
    "$ R^2$误差能较好的解决上述问题   \n",
    "$$R^2=1-\\frac{\\sum_{i = 0} ^m(y^i - h_\\theta (x^i)^2}{\\sum_{i = 0} ^m(y^i - \\bar y)^2}$$\n",
    "$R^2\\leq1$，$R^2$越大越好  \n",
    "当$R^2<0$时，模型误差大于基准模型$y=\\bar y$，可能数据不存在任何线性关系    \n",
    "同时，$$R^2=1-\\frac{MSE(y,h_\\theta (x^i))}{var( y )}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[sklearn.metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) 集成了众多评价指标类，根据不同需求可以自行选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
